---
title: "Modelo Jerárquico Normal"
author: 
- Juan Sosa PhD
- Webpage https://sites.google.com/view/juansosa/ 
- YouTube https://www.youtube.com/c/JuanSosa1702 
- GitHub  https://github.com/jstats1702 
- Rpubs   https://rpubs.com/jstats1702
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Motivación

Se considera la **media de las observaciones** registradas por medio de varios **dispositivos** acerca de la **temperatura de la superficie del mar** (SST, por sus siglas en inglés) en $^\text{o}$C, junto con el **tipo de dispositivo** (cuatro categorías: **bucket**, **eri**, **d.buoy**, **f.buoy**) con sus respectivas **ubicaciones** (latitud y longitud) en el **mar Mediterráneo en diciembre de 2003**. 

```{r, eval = TRUE, echo=FALSE, out.width="80%", fig.pos = "H", fig.align = "center"}
knitr::include_graphics("bucket.jpg")
```

El **objetivo** consiste en ajustar un **modelo probabilístico** para:

- Investigar el **proceso generativo** de las observaciones.
- Evaluar la asociación entre las **covariables** y las observaciones.
- Caracterizar las **propiedades estructurales** de las observaciones.
- Imputar **observaciones faltantes**.
- Predecir **observaciones futuras**.
- Cuantificar la **incertidumbre**.

# Datos

La base de datos `sst.dat` contiene $m = 86$ registros de la forma
$$
\left[\,\text{id}_j,\text{latitud}_j,\text{longitud}_j,\bar{y}_j,n_j,\text{tipo}_j\,\right]
$$
donde $\bar{y}_j=\frac{1}{n_j}\sum_{i=1}^{n_j} y_{i,j}$ es el promedio de las $n_j$ temperaturas registradas por el dispositivo $j$, para $j=1,\ldots,m$.

```{r}
# datos
df <- read.table(file = "sst.dat", header = T)
dim(df)
head(df)
```

```{r}
# datos por dispositivo
df1 <- df[df$type == "bucket",] # 1 = bucket
df2 <- df[df$type == "eri"   ,] # 2 = eri
df3 <- df[df$type == "d.buoy",] # 3 = d.buoy
df4 <- df[df$type == "f.buoy",] # 4 = f.buoy
df  <- rbind(df1,df2,df3,df4)
# tamaños
m1 <- nrow(df1)
m2 <- nrow(df2)
m3 <- nrow(df3)
m4 <- nrow(df4)
df$cod <- c(rep(1,m1), rep(2,m2), rep(3,m3), rep(4,m4))
table(factor(df$type, levels = c("bucket","eri","d.buoy","f.buoy")))
```

```{r, fig.width=5,fig.height=5, fig.align="center"}
# mapa usando RgoogleMaps
suppressMessages(suppressWarnings(library(RgoogleMaps)))
center <- c(median(df$lat), median(df$lon))
zoom   <- min(MaxZoom(range(df$lat), range(df$lon)))
mymap  <- GetMap(center = center, zoom = zoom, destfile = "medsea.png", maptype = "mobile")
PlotOnStaticMap(mymap, lat = df$lat, lon = df$lon, col = df$cod, pch = 20)
```

Los tipos de dispositivos son $\color{black}{\text{bucket}}$, $\color{red}{\text{eri}}$, $\color{green}{\text{d.buoy}}$, $\color{blue}{\text{d.buoy}}$.

# Análisis exploratorio de datos

```{r}
# n de dispositivos (grupos)
m <- nrow(df)
m
```


```{r}
# variable respuesta
y <- df$temp
summary(y)
```


```{r}
# tamaños de muestra
nj <- df$n
table(nj)
```


```{r, fig.width=8,fig.height=8, fig.align='center'}
# histograma
par(mfrow = c(2,2), mar = c(3,3,1,1), mgp = c(1.75,.75,0))
hist(df$temp, freq = F, xlim = c(14,26), ylim = c(0,0.28), col = "gray90", border = "gray90", xlab = "SST promedio", ylab = "Densidad", main = "", cex.axis = 0.8)
curve(expr = dnorm(x, mean = mean(df$temp), sd = sd(df$temp)), col = 1, lty = 1, add = T)
# cajas
boxplot(df1$temp, df2$temp, df3$temp, df4$temp, outline = F, ylim = c(15,22), col = 0, border = 1:4, boxwex = 0.5, xlab = "Tipo", ylab = "SST promedio", main = "", cex.axis = 0.8)
axis(side = 1, at = 1:4, labels = c("bucket","eri","d.buoy","f.buoy"), cex.axis = 0.8)
lines(x = jitter(x = df$cod, amount = .15), y = df$temp, type = "p", pch = 20, col = adjustcolor(col = df$cod, alpha.f = 0.3), cex = 1.2)
# dispersograma
plot (x = df$n, y = df$temp, xlab = "Tamaño de la muestra", ylab = "SST promedio", type = "n")
lines(x = df$n, y = df$temp, type = "p", col = adjustcolor(col = df$cod, alpha.f = 0.3), pch = 20, cex = 1.2)
# locacion
plot (x = df$lon, y = df$lat, xlab = "Longitud", ylab = "Latitud", type = "n", cex.axis = 0.8)
lines(x = df$lon, y = df$lat, type = "p", col = adjustcolor(col = df$cod, alpha.f = 0.3), pch = 20, cex = df$temp/7)
```

# Modelamiento

Los $m$ registros se asumen como **grupos independientes**, cada uno con $n_j$ observaciones $y_{1,j},\ldots,y_{n_j,j}$ condicionalmente independientes normalmente distribuidas con media $\mu_j$ y varianza $\sigma^2_j$, i.e., $y_{i,j}\mid\mu_j,\sigma^2_j \stackrel{\text{iid}}{\sim} \textsf{N}(\mu_j,\sigma^2_j)$, lo que significa que
$$
\bar{y}_j\mid\mu_j,\sigma^2_j \stackrel{\text{ind}}{\sim} \textsf{N}(\mu_j,\sigma^2_j/n_j)
$$
donde $\bar{y}_j=\frac{1}{n_j}\sum_{i=1}^{n_j} y_{i,j}$, para $j = 1,\ldots,m$.

Para introducir la **asociación** entre la repuesta media de las observaciones $\mu_j$ y las covariables $x_{j,1},\ldots,x_{j,p}$, se considera el predictor lineal $\eta_j=\boldsymbol{x}_j^{\textsf{T}}\boldsymbol{\beta} = \sum_{k=1}^p \beta_k x_{j,k}$ por medio de una dependencia estocástica Normal de la forma
$$
\mu_j\mid\boldsymbol{\beta},\tau^2 \stackrel{\text{iid}}{\sim} \textsf{N}(\boldsymbol{x}_j^{\textsf{T}}\boldsymbol{\beta},\tau^2)
$$
donde $\boldsymbol{x}_j=(x_{j,1},\ldots,x_{j,p})$ y $\boldsymbol{\beta}=(\beta_1,\ldots,\beta_p)$.

Se observa que bajo esta formulación se tiene que
$$
p(\bar{y}_j\mid\boldsymbol{\beta},\sigma^2_j,\tau^2) = \int_{\mathbb{R}} p(\bar{y}_j,\mu_j\mid\boldsymbol{\beta},\sigma^2_j,\tau^2)\,\text{d}\mu_j = \textsf{N}(\bar{y}_j\mid\boldsymbol{x}_j^{\textsf{T}}\boldsymbol{\beta},\sigma^2_j/n_j+\tau^2)\,.
$$

En resumen,
$$
\bar{\boldsymbol{y}}\mid\boldsymbol{\mu},\boldsymbol{\sigma}^2\sim\textsf{N}_m(\boldsymbol{\mu},\textsf{diag}(\sigma^2_1/n_1,\ldots,\sigma^2_m/n_m))
\qquad\text{y}\qquad
\boldsymbol{\mu}\mid\boldsymbol{\beta},\tau^2\sim\textsf{N}_m(\mathbf{X}\boldsymbol{\beta},\tau^2\mathbf{I})
$$
donde $\bar{\boldsymbol{y}}=(\bar{y}_1,\ldots,\bar{y}_m)$, $\boldsymbol{\mu}=(\mu_1,\ldots,\mu_m)$, $\boldsymbol{\sigma}^2=(\sigma^2_1,\ldots,\sigma^2_m)$ y $\mathbf{X}=(\boldsymbol{x}_1^{\textsf{T}},\ldots,\boldsymbol{x}_m^{\textsf{T}})$.

Para la **estructura de regresión** se considera la previa impropia
$$
p(\boldsymbol{\beta},\log\tau^2) \propto 1
\qquad\Longleftrightarrow \qquad
p(\boldsymbol{\beta},\tau^2) \propto \frac{1}{\tau^2}
$$
la cual no requiere la especificación de hiperparámetros.

Los **componentes de intra-varianza** se modelan jerárquicamente mediante 
$$
\sigma^2_j\mid\nu,\upsilon^2 \stackrel{\text{iid}}{\sim} \textsf{GI}(\nu/2,\nu\upsilon^2/2)\,,\qquad
p(\nu)\propto e^{-\lambda_0\nu}
\qquad\text{y}\qquad
\upsilon^2\sim\textsf{G}(\alpha_0/2,\beta_0/2)\,.
$$

Los **parámetros del modelo** son $\boldsymbol{\mu}$, $\boldsymbol{\sigma}^2$, $\boldsymbol{\beta}$, $\tau^2$, $\nu$ y $\upsilon^2$.

Los **hiperparámetros del modelo** son $\lambda_0$, $\alpha_0$ y $\beta_0$. 

```{r, eval = TRUE, echo=FALSE, out.width="50%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("ejemplo regresion 2.jpg")
```

# Ajuste del modelo

## Distribución posterior

La **distribución posterior** de $\mathbf{\Theta} = (\boldsymbol{\mu},\boldsymbol{\sigma}^2,\boldsymbol{\beta},\tau^2,\nu,\upsilon^2)$ es

$$
\begin{align*}
p(\mathbf{\Theta}\mid \bar{\boldsymbol{y}}) 
&\propto \prod_{j=1}^m \textsf{N}(\bar{y}_j\mid\mu_j,\sigma^2_j/n_j) \\
&\hspace{1cm}\times \prod_{j=1}^m \textsf{N}(\mu_j\mid\boldsymbol{x}_j^{\textsf{T}}\boldsymbol{\beta},\tau^2) \times \prod_{j=1}^m \textsf{GI}(\sigma^2_j\mid\nu/2,\nu\upsilon^2/2)\\
&\hspace{2cm}\times \frac{1}{\tau^2} \times e^{-\lambda_0\nu} \times \textsf{G}(\upsilon^2\mid\alpha_0/2,\beta_0/2)\,.
\end{align*}
$$

## Distribuciones condicionales completas

Las **distribuciones condicionales completas** para implementar un **muestreador de Gibbs** son:

- La distribución condicional completa de $\mu_j$ es $\mu_j\mid\text{resto}\sim\textsf{N}(m_j,v_j^2)$ con:
$$
m_j = \frac{\frac{1}{\tau^2}\,\boldsymbol{x}^{\textsf{T}}_j\boldsymbol{\beta} + \frac{n_j}{\sigma^2_j}\,\bar{y}_j}{\frac{1}{\tau^2} + \frac{n_j}{\sigma^2_j}}
\qquad\text{y}\qquad
v^2_j = \frac{1}{\frac{1}{\tau^2} + \frac{n_j}{\sigma^2_j}}\,.
$$
  Alternativamente, la distribución condicional completa de $\boldsymbol{\mu}$ es $\boldsymbol{\mu}\mid\text{resto}\sim\textsf{N}(\boldsymbol{m}.\mathbf{V})$ con:
$$
\boldsymbol{m} = \left(\tfrac{1}{\tau^2}\mathbf{I} + \mathbf{D}^{-1} \right)^{-1}\left(\tfrac{1}{\tau^2}\mathbf{X}\boldsymbol{\beta} + \mathbf{D}^{-1}\bar{\boldsymbol{y}}\right)
\qquad\text{y}\qquad
\mathbf{V} = \left(\tfrac{1}{\tau^2}\mathbf{I} + \mathbf{D}^{-1} \right)^{-1}\,.
$$
  donde $\mathbf{D}^{-1} = \textsf{diag}(n_1/\sigma^2_1,\ldots,n_m/\sigma^2_m)$.
  
```{r}
sample_mu <- function(sj, X, nj, m, sig2, bet, tau2) 
{
  vj <- 1/(1/tau2 + nj/sig2)
  c(rnorm(n = m, mean = vj*(c(X%*%bet)/tau2 + sj/sig2), sd = sqrt(vj)))
}
```

- La distribución condicional completa de $\sigma^2_j$ es $\sigma^2_j\mid\text{resto}\sim\textsf{GI}(a_j,b_j)$ con:
$$
a_j = \frac{\nu+1}{2}
\qquad\text{y}\qquad
b_j = \frac{\nu\upsilon^2 + n_j(\bar{y}_j - \mu_j)^2}{2}\,.
$$

```{r}
sample_sig2 <- function(y, nj, m, mu, nu, ups2) 
{
  c(1/rgamma(n = m, shape = 0.5*(nu + 1), rate = 0.5*(nu*ups2 + nj*(y - mu)^2)))
}
```

- La distribución condicional completa de $\boldsymbol{\beta}$ es $\boldsymbol{\beta}\mid\text{resto}\sim\textsf{N}(\boldsymbol{m},\mathbf{V})$ con:
$$
\boldsymbol{m} = \tau^2(\mathbf{X}^{\textsf{T}}\mathbf{X})^{-1}
\qquad\text{y}\qquad
\mathbf{V} = (\mathbf{X}^{\textsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\textsf{T}}\boldsymbol{\mu}\,.
$$

```{r}
sample_bet <- function(H, XtXi, mu, tau2)
{
  c(mvtnorm::rmvnorm(n = 1, mean = H%*%mu, sigma = tau2*XtXi))
}
```

- La distribución condicional completa de $\tau^2$ es $\tau^2\mid\text{resto}\sim\textsf{GI}(a,b)$ con:
$$
a = \frac{m}{2}
\qquad\text{y}\qquad
b = \frac{(\boldsymbol{\mu} - \mathbf{X}\boldsymbol{\beta})^{\textsf{T}}(\boldsymbol{\mu} - \mathbf{X}\boldsymbol{\beta})}{2}\,.
$$

```{r}
sample_tau2 <- function(X, m, mu, bet)
{
  1/rgamma(n = 1, shape = 0.5*m, rate = 0.5*sum((mu - c(X%*%bet))^2))
}
```

- La distribución condicional completa de $\nu$ es:
$$
\log p(\nu\mid\text{resto}) \propto \frac{m\nu}{2}\log\left(\frac{\nu\upsilon^2}{2}\right) - m\log\Gamma\left(\frac{\nu}{2}\right) - \frac{\nu}{2}\sum_{j=1}^m\log\sigma^2_j - \nu\left( \lambda_0 + \frac{\upsilon}{2} \sum_{j=1}^m \frac{1}{\sigma^2_j}  \right)\,.
$$

```{r}
sample_nu <- function(m, la0, sig2, nus, ups2) 
{
  lp <- 0.5*m*nus*log(0.5*nus*ups2) - m*lgamma(0.5*nus) - 0.5*nus*sum(log(sig2)) - nus*(la0 + 0.5*ups2*sum(1/sig2))
  sample(x = nus, size = 1, replace = F, prob = exp(lp - max(lp)))
}
```

- La distribución condicional completa de $\upsilon^2$ es $\upsilon^2\mid\text{resto}\sim\textsf{G}(a,b)$ con:
$$
a = \frac{\alpha_0 + m\nu}{2}
\qquad\text{y}\qquad
b = \frac{\beta_0 + \nu\sum_{j=1}^m\frac{1}{\sigma^2_j}}{2}\,.
$$

```{r}
sample_ups2 <- function(m, al0, be0, sig2, nu)
{
  rgamma(n = 1, shape = 0.5*(al0 + m*nu), rate = 0.5*(be0 + nu*sum(1/sig2)))
}
```

## Muestreador de Gibbs

El **muestreador de Gibbs** para obtener muestras de la **distribución posterior** de $\mathbf{\Theta}$ es:

1. Establecer el valor inicial de los parámetros.
2. Actualizar el valor de los parámetros por medio de las distribuciones condicionales completas correspondientes.
3. Almacenar  el valor de los parámetros simulados.

```{r}
# MCMC
MCMC <- function (niter, nburn, nskip, y, X, nj, al0, be0, la0, nus, verbose = TRUE) 
{
  # numero iteraciones
  B <- nburn + nskip*niter
  ncat <- floor(0.1*B)
  # constantes
  m    <- nrow(X)
  p    <- ncol(X)
  s2y  <- var(y)
  sj   <- c(nj*y)
  XtXi <- solve(t(X)%*%X)
  H    <- solve(t(X)%*%X)%*%t(X)
  # inicializacion
  mu   <- c(y)
  sig2 <- c(rep(s2y, m))
  bet  <- c(H%*%mu)
  tau2 <- c(sum((mu - X%*%bet)^2)/(m - p))
  nu   <- c(1)
  ups2 <- c(s2y)
  # almacenamiento
  MU <- SIG2 <- BET <- TAU2 <- NU <- UPS2 <- LP <- NULL
  # cadena
  set.seed(1234)
  for (b in 1:B) {
    # actualizar
    mu   <- sample_mu  (sj, X, nj, m, sig2, bet, tau2)
    sig2 <- sample_sig2(y, nj, m, mu, nu, ups2)
    bet  <- sample_bet (H, XtXi, mu, tau2)
    tau2 <- sample_tau2(X, m, mu, bet)
    ups2 <- sample_ups2(m, al0, be0, sig2, nu)
    nu   <- sample_nu  (m, la0, sig2, nus, ups2)
    # almacenar y log-verosimilitud
    if (b > nburn) {
      if (b%%nskip == 0) {
        MU   <- rbind(MU,   mu)
        SIG2 <- rbind(SIG2, sig2)
        BET  <- rbind(BET,  bet)
        TAU2 <- rbind(TAU2, tau2)
        NU   <- rbind(NU,   nu)
        UPS2 <- rbind(UPS2, ups2)
        LP   <- rbind(LP,   sum(dnorm(x = y, mean = mu, sd = sqrt(sig2/nj), log = T)))
      }
    }
    # progreso
    if (verbose) if (b%%ncat == 0) cat(100*round(b/B, 1), "% completado \n", sep = "")
  }
  # retorno
  list(MU = MU, SIG2 = SIG2, BET = BET, TAU2 = TAU2, NU = NU, UPS2 = UPS2, LP = LP)
}
```

## Selección de los hiperparámetros

Se escoge $\lambda_0 = 1$ y $\alpha_0 = 8$ y $\beta_0 = 4.078888$ tales que
$$
\textsf{E}(\upsilon^2) = \frac{\alpha_0}{\beta_0} := \,s^2_{\bar{y}}
\qquad\text{y}\qquad
\textsf{CV}(\upsilon^2) = \sqrt{\frac{2}{\alpha_0}} := 50\%
$$
donde $s^2_{\bar{y}}=\frac{1}{m-1}\sum_{j=1}^m(\bar{y}_j-\bar{\bar{y}})^2$, con $\bar{\bar{y}}=\frac{1}{m}\sum_{j=1}^m \bar{y}_j$, de manera que $\sigma^2_j$ esté débilmente concentrado al rededor de $s^2_{\bar{y}}$, 

```{r, fig.align='center'}
# distr. previa de nu
la0 <- 1
# rango nu
nus <- 1:20
# grafico
par(mfrow = c(1,1), mar = c(5,3,1,1), mgp = c(1.75,.75,0))
plot (x = nus, y = exp(-0.5*nus), type = "h", lwd = 2, xlab = expression(nu), ylab = expression(p(nu)))
```

```{r, fig.align='center'}
# distr. previa de upsilon
al0 <- 2*(0.5)^(-2)
al0
be0 <- al0/var(y)
be0
# grafico
par(mfrow = c(1,1), mar = c(5,3,1,1), mgp = c(1.75,.75,0))
curve(expr = dgamma(x, shape = al0/2, rate = be0/2), from = 0, to = 10, lwd = 2, xlab = expression(upsilon^2), ylab = expression(p(upsilon^2)))

```
## Matriz de diseño

Se define la matriz de diseño tal que $\boldsymbol{x}_j=(x_{j,1},\ldots,x_{j,12})$ con

- $x_{j,1}  = 1$.
- $x_{j,2}  = 1$ si $\text{tipo}_j = \text{eri}$    y $x_{2,j} = 0$ en otro caso.
- $x_{j,3}  = 1$ si $\text{tipo}_j = \text{d.buoy}$ y $x_{3,j} = 0$ en otro caso.
- $x_{j,4}  = 1$ si $\text{tipo}_j = \text{f.buoy}$ y $x_{4,j} = 0$ en otro caso.
- $x_{j,5}  = \text{latitud}_{j}$.
- $x_{j,6}  = \text{latitud}_{j}\times x_{2_j}$.
- $x_{j.7}  = \text{latitud}_{j}\times x_{3_j}$.
- $x_{j,8}  = \text{latitud}_{j}\times x_{4_j}$.
- $x_{j,9}  = \text{longitud}_{j}$.
- $x_{j,10} = \text{longitud}_{j}\times x_{2_j}$.
- $x_{j,11} = \text{longitud}_{j}\times x_{3_j}$.
- $x_{j,12} = \text{longitud}_{j}\times x_{4_j}$

de forma que

- Si $\text{tipo}_j = \text{bucket}$, entonces:
$$
\textsf{E}(\mu_j\mid\boldsymbol{x}_j,\boldsymbol{\beta}) = \beta_1 + \beta_5\,\text{latitud}_j + \beta_9\,\text{longitud}_j\,.
$$
- Si $\text{tipo}_j = \text{eri}$, entonces:
$$
\textsf{E}(\mu_j\mid\boldsymbol{x}_j,\boldsymbol{\beta}) = (\beta_1+\beta_2) + (\beta_5+\beta_6)\,\text{latitud}_j + (\beta_9+\beta_{10})\,\text{longitud}_j\,.
$$
- Si $\text{tipo}_j = \text{d.buoy}$, entonces:
$$
\textsf{E}(\mu_j\mid\boldsymbol{x}_j,\boldsymbol{\beta}) = (\beta_1+\beta_3) + (\beta_5+\beta_7)\,\text{latitud}_j + (\beta_9+\beta_{11})\,\text{longitud}_j\,.
$$
- Si $\text{tipo}_j = \text{f.buoy}$, entonces:
$$
\textsf{E}(\mu_j\mid\boldsymbol{x}_j,\boldsymbol{\beta}) = (\beta_1+\beta_4) + (\beta_5+\beta_8)\,\text{latitud}_j + (\beta_9+\beta_{12})\,\text{longitud}_j\,.
$$

```{r}
# matriz de diseño
X5 <- as.matrix(df$lat)
X9 <- as.matrix(df$lon)
X2 <- as.matrix(c(rep(0,m1), rep(1,m2), rep(0,m3), rep(0,m4)))
X3 <- as.matrix(c(rep(0,m1), rep(0,m2), rep(1,m3), rep(0,m4)))
X4 <- as.matrix(c(rep(0,m1), rep(0,m2), rep(0,m3), rep(1,m4)))
X  <- cbind(1, X2, X3, X4, X5, X2*X5, X3*X5, X4*X5, X9, X2*X9, X3*X9, X4*X9)
m  <- nrow(X)
p  <- ncol(X)
dim(X)
```

## Implementación


```{r}
# n de parametros
2*m+p+3
```


```{r, eval}
# iteraciones
nskip <- 100
nburn <- 1000
niter <- 1000
```


```{r, eval=FALSE}
# ajuste del modelo
set.seed(1)
muestras <- MCMC(niter, nburn, nskip, y, X, nj, al0, be0, la0, nus, verbose = T)
save(muestras, file = "muestras_regr2.RData")
```


## Cadena de la log-verosimilitud


```{r}
# cargar muestras
load(file = "muestras_regr2.RData")
```


```{r, echo=FALSE, fig.align='center'}
# cadenas
par(mfrow = c(1,1), mar = c(3,3.2,1,1), mgp = c(1.75,.75,0))
plot(x = 1:niter, y = muestras$LP  [,1], type = "l", col = 1, main = "", xlab = "Iteración", ylab = "Log-verosimilitud", cex.axis = 0.8)
```


## Errores estándar de Monte Carlo:


```{r, echo=F}
# errores estandar de Monte Carlo
EEMC <- c(apply(muestras$MU,   2, sd)/sqrt(coda::effectiveSize(muestras$MU  )),
          apply(muestras$SIG2, 2, sd)/sqrt(coda::effectiveSize(muestras$SIG2)),
          apply(muestras$BET,  2, sd)/sqrt(coda::effectiveSize(muestras$BET )),
          sd(muestras$TAU2)/sqrt(coda::effectiveSize(muestras$TAU2)),
          sd(muestras$UPS2)/sqrt(coda::effectiveSize(muestras$UPS2)))
round(summary(EEMC), 3)
```

```{r, echo=F, fig.align='center'}
boxplot(EEMC, outline = F, xlim = c(1,1), ylim = range(EEMC), col = 0, boxwex = 0.4)
axis(side = 1, at = 1, labels = c("EEMC"),  cex.axis = 0.8)
lines(x = jitter(x = rep(1,length(EEMC)), amount = .1), y = EEMC, type = "p", pch = 20, col = adjustcolor(col = 1, alpha.f = 0.3), cex = 1.3)
```


# Inferencia


```{r, echo=F}
summ <- function(x) c(mean(x), sd(x), quantile(x, c(0.025,0.975)))
musumm   <- apply(X = muestras$MU,   MARGIN = 2, FUN = summ)
sig2summ <- apply(X = muestras$SIG2, MARGIN = 2, FUN = summ)
betsumm  <- apply(X = muestras$BET, MARGIN = 2, FUN = summ)
color    <- c(rep(16,m1), rep(4,m2), rep(2,m3), rep(3,m4)) 
```


## Medias específicas $\mu_j$


```{r, echo=F, fig.height=5, fig.width=10, fig.align='center'}
par(mfrow = c(1,1), mar = c(3,3.3,1,1), mgp = c(1.75,.75,0))
plot(x = NA, y = NA, xlim = c(1,m), ylim = c(15,24), xlab = 'Dispositivo', ylab = expression(mu[j]), cex.axis = 0.8)
for (j in 1:m) {
  segments(x0 = j, y0 = musumm[3,j], x1 = j, y1 = musumm[4,j], col = color[j])
  points(x = j, y = musumm[1,j], cex = 1.1, pch = 20, col = color[j])
}
lines(x = 1:m, y = y, type = "p", pch = 15, cex = 0.6)
legend('top', legend = c('Dato','bucket','eri','f.buoy','d.bouy'), bty = 'n', fil = c(1,16,4,2,3), border = c(1,16,4,2,3), col = c(1,16,4,2,3), cex = 1, horiz = T, text.width = 10)
```

## Varianzas específicas $\sigma^2_j$


```{r, echo=F, fig.height=5, fig.width=10, fig.align='center'}
par(mfrow = c(1,1), mar = c(3,3.3,1,1), mgp = c(1.75,.75,0))
plot(x = NA, y = NA, xlim = c(1,m), ylim = c(0,26), xlab = 'Dispositivo', ylab = expression(sigma[j]^2), cex.axis = 0.8)
for (j in 1:m) {
  segments(x0 = j, y0 = sig2summ[3,j], x1 = j, y1 = musumm[4,j], col = color[j])
  points(x = j, y = sig2summ[1,j], cex = 1, pch = 20, col = color[j])
}
legend('top', legend = c('bucket','eri','f.buoy','d.bouy'), bty = 'n', fil = c(16,4,2,3), border = c(16,4,2,3), col = c(16,4,2,3), cex = 1, horiz = T, text.width = 10)
```

## Componentes de varianza $\tau^2$, $\upsilon^2$, $\nu$

```{r, echo=F, fig.height=4.5, fig.width=9, fig.align='center'}
par(mfrow = c(1,2), mar = c(3,3,1,1), mgp = c(1.75,.75,0))
hist(x = muestras$TAU2, freq = F, col = "gray90", border = "gray90", xlab = expression(tau^2), ylab = "Densidad", main = "", cex.axis = 0.8)
abline(v = quantile(muestras$TAU2, c(0.025,0.5,0.975)), col = c(4,2,4), lty = c(4,2,4), lwd = c(2,1,2))
hist(x = muestras$UPS2, freq = F, col = "gray90", border = "gray90", xlab = expression(upsilon^2), ylab = "Densidad", main = "", cex.axis = 0.8)
abline(v = quantile(muestras$UPS2, c(0.025,0.5,0.975)), col = c(4,2,4), lty = c(4,2,4), lwd = c(2,1,2))
```

```{r, echo=F, fig.height=4.5, fig.width=4.5, fig.align='center'}
par(mfrow = c(1,1), mar = c(3,3,1,1), mgp = c(1.75,.75,0))
plot(x = table(factor(muestras$NU, 1:max(muestras$NU)))/niter, type = "h", col = 1, xlab = bquote(nu), ylab = "Densidad", cex.axis = 0.8)
```


## Coeficientes de la regresión $\boldsymbol{\beta}$

```{r, echo=F, fig.height=8, fig.width=5, fig.align='center'}
par(mfrow = c(2,1), mar = c(3,3,1,1), mgp = c(1.75,.75,0))
plot(x = NA, y = NA, xlim = c(1,p), ylim = c(-1,1)*100, type = "n", xlab = 'Regresor', ylab = expression(beta[j]), xaxt = 'n', cex.axis = 0.75)
axis(side = 1, at = 1:p, cex.axis = 0.75, las = 2)
abline(h = 0,   col = 2, lty = 1)
for (j in 1:p) {
  segments(x0 = j, y0 = betsumm[3,j], x1 = j, y1 = betsumm[4,j], col = 1)
  points(x = j, y = betsumm[1,j], cex = 1, pch = 20, col = 1)
} 
plot(x = betsumm[1,], ylim = c(-1,1)*30, type = "n", lwd = 2, xlab = "Regresor", ylab = "Media posterior", xaxt = 'n', cex.axis = 0.75)
axis(side = 1, at = 1:p, cex.axis = 0.75, las = 2)
abline(h = 0, col = 2, lty = 1)
lines(betsumm[1,], type = "h", lwd = 3)
```



# Encogimiento

```{r, echo=F, fig.height=4.5, fig.width=9, fig.align='center'}
# encogimiento
mu_hat <- colMeans(muestras$MU)
par(mfrow = c(1,2), mar = c(3,3,1,1), mgp = c(1.75,.75,0))
plot(x = y, y = mu_hat, xlim = range(y,mu_hat), ylim = range(y,mu_hat), xlab = expression(bar(y)[j]), ylab = expression(hat(mu)[j]), col = adjustcolor(col = 1, alpha.f = 0.3), pch = 20, cex.lab = 0.8, cex = 1.2)
abline(a = 0, b = 1, col = 'red',lwd = 1, lty = 2)
plot(nj, y-mu_hat, ylab = expression(bar(y)[j]-hat(mu)[j]), ylim = c(-1,1)*4, xlab = "Tamaño muestra", col = adjustcolor(col = 1, alpha.f = 0.3), pch = 20, cex.lab = 0.8, cex = 1.2)
abline(h = 0, col = 'red', lwd = 1, lty = 2)
```

```{r, echo=F, fig.height=5, fig.width=6, fig.align='center'}
plot(x = NA, y = NA, xlim = range(y,mu_hat), ylim = c(1,4), yaxt = "n", cex.axis = 0.8, xlab = "SST", ylab = "", main = "")
axis(side = 2, at = c(2,3), labels = c(expression(hat(mu)[j]), expression(bar(y)[j])), las = 1)
abline(h = c(2,3), col = c(3,2))
for (j in 1:m) {
  segments(x0 = mu_hat[j], y0 = 2, x1 = y[j], y1 = 3)
}
```


# Estadísticos de prueba


```{r, echo=F}
test_stats <- function(x) c(mean(x), median(x), sd(x), diff(quantile(x, c(0.25,0.75))))
ts_display <- c("Media","Mediana","Desv. Estandar","Rango Intercuartilico")
TS <- NULL
set.seed(1)
for (b in 1:niter) {
  mu   <- muestras$MU  [b,]
  sig2 <- muestras$SIG2[b,]
  TS   <- rbind(TS, test_stats(rnorm(n = m, mean = mu, sd = sqrt(sig2/nj))))
}
TS0 <- test_stats(y)
```


```{r, echo=F, fig.height=9, fig.width=9, fig.align='center'}
par(mfrow = c(2,2), mar = c(3,3,2,1), mgp = c(1.75,.75,0))
for (j in 1:length(TS0)) {
  ts  <- TS[,j]
  ts0 <- TS0[j]
  hist(x = ts, freq = F, col = "gray90", border = "gray90", xlab = ts_display[j], ylab = "Densidad", main = ts_display[j])
  abline(v = quantile(ts, c(0.025,0.5,0.975)), col = c(4,2,4), lty = c(4,2,4), lwd = c(2,1,2))
  abline(v = ts0, lwd = 2)
}
```


# Predicción


```{r}
# prediccion
set.seed(1)
# tamaño del grupo
g  <- df$type
j1 <- sample(x = which((g == "bucket") & (nj == max(nj[g == "bucket"]))), size = 1)
j2 <- sample(x = which((g == "eri"   ) & (nj == max(nj[g == "eri"   ]))), size = 1)
j3 <- sample(x = which((g == "d.buoy") & (nj == max(nj[g == "d.buoy"]))), size = 1)
j4 <-            which((g == "f.buoy") & (nj == max(nj[g == "f.buoy"])))
# grilla
ng <- 25
gx <- seq(min(X[,9]), max(X[,9]), len = ng) # lon
gy <- seq(min(X[,5]), max(X[,5]), len = ng) # lat
# predictiva posterior
z1 <- z2 <- z3 <- z4 <- array(data = NA, dim = c(ng,ng,niter)) 
for (i in 1:ng) {
  for (j in 1:ng) {
    lon <- gx[i]
    lat <- gy[j]
    for (b in 1:niter) {
      bet  <- muestras$BET[b,]
      sig2 <- muestras$SIG2[b,]
      z1[i,j,b] <- rnorm(n = 1, mean = sum(X[j1,]*bet), sd = sqrt(sig2[j1]/nj[j1]))
      z2[i,j,b] <- rnorm(n = 1, mean = sum(X[j2,]*bet), sd = sqrt(sig2[j2]/nj[j2]))
      z3[i,j,b] <- rnorm(n = 1, mean = sum(X[j3,]*bet), sd = sqrt(sig2[j3]/nj[j3]))
      z4[i,j,b] <- rnorm(n = 1, mean = sum(X[j4,]*bet), sd = sqrt(sig2[j4]/nj[j4]))
    }
  }
}
```


```{r, echo=F, fig.height=4.5, fig.width=6.5, fig.align='center'}
par(mfrow = c(1,1), mar = c(3,3,2,1), mgp = c(1.75,.75,0))
filled.contour(x = gx, y = gy, z = apply(X = z1, MARGIN = c(1,2), FUN = mean), xlab = 'Longitud', ylab = 'Latitud', main = 'bucket', las=0)
```


```{r,  fig.height=4.5, fig.width=6.5, fig.align='center'}
par(mfrow = c(1,1), mar = c(3,3,1,1), mgp = c(1.75,.75,0))
coords <- expand.grid(gy, gx)
zz     <- c(apply(X = z1, MARGIN = c(1,2), FUN = mean))
col.br <- colorRampPalette(c('blue','cyan','yellow','red'))
surf   <- MBA::mba.surf(xyz = cbind(coords, zz), no.X = 250, no.Y = 250, m = 2, h = 5, extend = FALSE)$xyz.est 
fields::image.plot(surf, col = col.br(100), xlim = range(coords[,1]), ylim = range(coords[,2]), xaxs = 'r', yaxs='r', xlab = 'Longitud', ylab = 'Latitud', main = 'bucket')
contour(surf, add=TRUE)
```

# Error cuadrático medio

```{r}
# estimacion
zz1 <- c(apply(X = z1, MARGIN = c(1,2), FUN = mean))
zz2 <- c(apply(X = z2, MARGIN = c(1,2), FUN = mean))
zz3 <- c(apply(X = z3, MARGIN = c(1,2), FUN = mean))
zz4 <- c(apply(X = z4, MARGIN = c(1,2), FUN = mean))
```


```{r}
# error cuadratico medio respecto a la temperatura promedio
yb <- sum(y*nj)/sum(nj)
tab <- rbind(c(mean(zz1), sqrt(sum((zz1 - yb)^2)/length(zz1)), m1, sum(df1$n)),
             c(mean(zz2), sqrt(sum((zz2 - yb)^2)/length(zz2)), m2, sum(df2$n)),
             c(mean(zz3), sqrt(sum((zz3 - yb)^2)/length(zz3)), m3, sum(df3$n)),
             c(mean(zz4), sqrt(sum((zz4 - yb)^2)/length(zz4)), m4, sum(df4$n)))
colnames(tab) <- c("Media","RMSE","n disp","n total")
rownames(tab) <- c("bucket","eri","d.buoy","f.buoy")
round(tab,2)
```

```{r}
# National Oceanic and Atmospheric Administration (NOAA)
# error cuadratico medio respecto a NOAA en 2012
yb <- 22.44
tab <- rbind(c(mean(zz1), sqrt(sum((zz1 - yb)^2)/length(zz1)), m1, sum(df1$n)),
             c(mean(zz2), sqrt(sum((zz2 - yb)^2)/length(zz2)), m2, sum(df2$n)),
             c(mean(zz3), sqrt(sum((zz3 - yb)^2)/length(zz3)), m3, sum(df3$n)),
             c(mean(zz4), sqrt(sum((zz4 - yb)^2)/length(zz4)), m4, sum(df4$n)))
colnames(tab) <- c("Media","RMSE","n disp","n total")
rownames(tab) <- c("bucket","eri","d.buoy","f.buoy")
round(tab,2)
```