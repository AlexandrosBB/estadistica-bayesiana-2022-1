---
title: "Modelo Jerárquico Normal 1"
author: 
- Juan Sosa PhD
- Webpage https://sites.google.com/view/juansosa/ 
- YouTube https://www.youtube.com/c/JuanSosa1702 
- GitHub  https://github.com/jstats1702 
- Rpubs   https://rpubs.com/jstats1702
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

El tipo más simple de **datos multinivel** tiene **dos niveles**, en los que un nivel consiste de **grupos** y el otro consiste en **unidades dentro de los grupos**. 

Se denota con $y_{i,j}$ la observación de la unidad $i$ en el grupo $j$, para $i = 1,\ldots,n_j$ y $j=1,\ldots,m$, donde $m$ es el número de grupos y $n = \sum_{j=1}^m n_j$ es el tamaño de la muestra.

El **conjunto de datos** es $\boldsymbol{y} = (\boldsymbol{y}_1,\ldots,\boldsymbol{y}_m)$, donde $\boldsymbol{y}_j=(y_{1,j},\ldots,y_{n_j,j})$ son las observaciones asociadas con el grupo $j$, para $j=1,\ldots,m$.

# Modelo

Un modelo popular para describir la **heterogeneidad de las medias** en varias poblaciones es el modelo jerárquico normal, en el cual la **variabilidad dentro y entre** se modela usando **distribuciones normales**:

- Caracterización **dentro** de los grupos:
$$
y_{i, j}\mid\theta_j,\sigma^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\theta_j,\sigma^2\right)
$$
- Caracterización **entre** los grupos:
$$
\theta_{j}\mid\mu,\tau^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\mu,\tau^2\right)
$$
- Distribución **previa**:
$$
p(\sigma^2,\mu,\tau^2) = p(\sigma^2)\,p(\mu)\,p(\tau^2)
$$
donde
$$
\sigma^2\sim\textsf{GI}\left(\tfrac{\nu_0}{2},\tfrac{\nu_0\,\sigma^2_0}{2}\right)\qquad\mu\sim\textsf{N}(\mu_0,\gamma_0^2)\qquad\tau^2\sim\textsf{GI}\left(\tfrac{\eta_0}{2},\tfrac{\eta_0\,\tau^2_0}{2}\right)
$$
- Los **parámetros** del modelo son $\boldsymbol{\theta}=(\theta_1,\ldots,\theta_m,\sigma^2,\mu,\tau^2)$.

- Los **hiper-parámetros** del modelo son $(\nu_0,\sigma^2_0,\mu_0,\gamma_0^2,\eta_0,\tau^2_0)$.


```{r, eval = TRUE, echo=FALSE, out.width="75%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("modelo_normal_jerarquico.png")
```

# Estimación

Construir un **muestreador de Gibbs** para obtener muestras de la distribución posterior $p(\boldsymbol{\theta}\mid\boldsymbol{y})$.

- Distribución **posterior**:
$$
\begin{aligned}
p(\boldsymbol{\theta} \mid \boldsymbol{y}) &\propto p(\boldsymbol{y} \mid \boldsymbol{\theta})\, p(\boldsymbol{\theta}) \\
&=  p(\boldsymbol{y}_1,\ldots,\boldsymbol{y}_m \mid \theta_1,\ldots\theta_m,\sigma^2)\times p(\theta_1,\ldots,\theta_m\mid\mu,\tau^2)\times p(\sigma^2,\mu,\tau^2) \\
&=\prod_{j=1}^m\prod_{i=1}^{n_j} \textsf{N}\left(y_{i, j} \mid \theta_{j}, \sigma^{2}\right) \times \prod_{j=1}^m \textsf{N}\left(\theta_{j} \mid \mu, \tau^{2}\right) \times \textsf{GI}\left(\sigma^{2} \mid \tfrac{\nu_{0}}{2}, \tfrac{\nu_{0}\,\sigma_{0}^{2}}{2} \right) \times \textsf{N}\left(\mu \mid \mu_{0}, \gamma_{0}^{2}\right) \times \textsf{GI}\left(\tau^{2} \mid \tfrac{\eta_{0}}{2}, \tfrac{\eta_{0}\,\tau_{0}^{2}}{2}\right)
\end{aligned}
$$

Distribuciones **condicionales completas**:
$$
\begin{aligned}
p\left(\theta_{j} \mid \text { resto }\right) &=\textsf{N}\left(\theta_{j} \,\Big|\, \frac{\mu / \tau^{2} + n_{j} \bar{y}_{j} / \sigma^{2}}{1 / \tau^{2} + n_{j} /\sigma^{2}}, \frac{1}{1 / \tau^{2} + n_{j} /\sigma^{2}}\right) \\
p\left(\sigma^{2} \mid \text { resto }\right) &=\textsf{GI}\left(\sigma^{2} \,\Big|\, \frac{\nu_{0}+\sum_{j=1}^m n_{j}}{2}, \frac{\nu_{0} \sigma_{0}^{2}+\sum_{j=1}^m \sum_{i=1}^{n_j}\left(y_{i, j}-\theta_{j}\right)^{2}}{2}\right) \\
p(\mu \mid \text { resto }) &=\textsf{N}\left(\mu \,\Big|\, \frac{\mu_{0} / \gamma_{0}^{2} + m \bar{\theta} / \tau^{2}}{1 / \gamma_{0}^{2} + m / \tau^{2}}, \frac{1}{1 / \gamma_{0}^{2} + m / \tau^{2}}\right) \\
p\left(\tau^{2} \mid \text { resto }\right) &=\textsf{ GI }\left(\tau^{2} \,\Big|\, \frac{\eta_{0}+m}{2}, \frac{\eta_{0} \tau_{0}^{2}+\sum_{j=1}^m\left(\theta_{j}-\mu\right)^{2}}{2}\right)
\end{aligned}
$$


# Ejemplo: Puntahes de Matemáticas

Los conjuntos de datos de los archivos `SB11\_1.txt` contiene el **código del departamento de ubicación del colegio** y el **puntaje de matemáticas de los estudiantes que presentaron la Prueba Saber 11 del primer semestre de 2020**. Estos datos son de carácter público y están disponibles en https://www.icfes.gov.co. 
Se recomienda consultar la *Guía de orientación Saber 11* (Icfes, 2020) para obtener más detalles sobre la prueba. 

La prueba de matemáticas se obtiene mediante un **modelo 3PL** (modelo logístico de 3 parámetros que define la probabilidad de responder correctamente de un individuo, en función de su habilidad, la dificultad del ítem, la discriminación del ítem y el pseudo-azar) y tiene una **escala de 0 a 100** (sin decimales), con **puntaje promedio de 50 puntos** y **desviación estándar 10 puntos** (Icfes, 2018, *Guía de diseño, producción, aplicación y calificación del examen Saber 11*, p. 33).

El objetivo es **construir un modelo predictivo para el puntaje de matemáticas a nivel nacional**, tomando como datos de entrenamiento (*training data*) los resultados del primer semestre de 2020 (15435 estudiantes), con el fin de **hacer inferencias sobre la población de estudiantes tanto a nivel nacional como departamental**. Por lo tanto, se toma como variable de agrupamiento el departamento de ubicación del colegio del estudiante. El *Diccionario de variables Saber 11* contiene la información detallada sobre las variables de las bases de datos.

## Estructura de los datos

```{r}
# settings
suppressMessages(suppressWarnings(library(dplyr))) 
suppressMessages(suppressWarnings(library(ggplot2))) 
# datos
SB11_1 <- read.csv("SB11_1.txt", sep=";")
colnames(SB11_1) <- c("DPTO","PUNTAJE")
# tamaños, respuesta, estadisticos
# y    : puntajes de los estudiantes (c)
# Y    : puntajes  de los estudiantes (list)
# g    : identificador de los departamentos (c)
# m    : numero de grupos (departamentos)
# n    : numero de estudiantes en cada departamento (c)
# ybar : promedios de los puntajes (c)
# s2   : varianzas de los puntajes (c)
m <- length(table(SB11_1$DPTO))
m
nj <- as.numeric(table(SB11_1$DPTO))
nj
n <- sum(nj)
n
# respuesta por grupos
y    <- SB11_1$PUNTAJE
ids  <- 1:m
ids2 <- c("Ant","Atl","Bog","Bol","Boy","Cal","Caq","Cau","Ces","Cor","Cun","Hui","Gua","Mag","Met","Nar","NSa","Qui","Ris","San","Tol","VaC","Ara","Cas","Put")
ybar <- NULL
s2   <- NULL
g    <- rep(NA,n)
Y    <- vector(mode = "list", length = m)
for (j in 1:m) {
  index    <- SB11_1$DPTO == unique(SB11_1$DPTO)[j]
  ybar[j]  <- mean(y[index])
  s2[j]    <- var (y[index])
  g[index] <- j
  Y[[j]]   <- y[index]
}
```
## Análisis exploratorio

```{r}
# Descargar shape files
# https://sites.google.com/site/seriescol/shapes
shp <- sf::st_read("depto.shp", quiet = T)
# promedio por departamento
dat_map <- SB11_1 %>% group_by(DPTO) %>% summarise("Media" = mean(PUNTAJE))
pd <- rbind(dat_map, data.frame(DPTO = c(27,70,88,91,94,95,97,99), Media = NA))
pd$DPTO <- as.character(pd$DPTO)
pd$DPTO[pd$DPTO == "5"] <- "05"
pd$DPTO[pd$DPTO == "8"] <- "08"
# plot
inner_join(x = shp, y = pd, by = c("DPTO")) %>% 
  select(DPTO, Media, geometry) %>%
  ggplot() +
  geom_sf(aes(fill = Media), size = 0.125, color = "#b2b2b2") +
  theme_bw() + 
  xlab("Longitud") + ylab("Latitud") +
  labs(title = "")
```

```{r, fig.width=10, fig.height=5}
# representacion de los puntajes brutos
par(mfrow=c(1,1),mar=c(4,4,1.5,1),mgp=c(2.5,.75,0))
plot(c(1,m), range(Y), type="n", xlab="Departamento", ylab="Puntaje", main="Ranking (promedio muestral)", xaxt="n")
for (l in 1:m) {
  j <- order(ybar)[l]
  points(rep(l, nj[j]), Y[[j]], pch=16, cex=.5)
  segments(l, min(Y[[j]]), l, max(Y[[j]]))
}
abline(h=mean(ybar))
axis(side = 1, at = 1:m, labels = ids2[order(ybar)], las = 2)
```

Es frecuente que los grupos con promedios muestrales muy altos o muy bajos correspondan a aquellos grupos con tamaños muestrales bajos, ya que $\textsf{Var}(\bar{y}) = \sigma^2/n$.

```{r, fig.width=10, fig.height=5}
par(mfrow=c(1,2),mar=c(3,3,1,1),mgp=c(1.75,.75,0)) 
hist(ybar, freq = F, main="", xlab="Promedio", ylab="Densidad", border="gray90", col="gray90")
plot(nj, ybar, xlab="Tamaño del grupo", ylab="Promedio", pch = 16, col="gray80")
```



## Modelo jerárquico Normal con medias específicas

**Distribución muestral:**
$$
y_{i, j}\mid\theta_j,\sigma^2 \stackrel{\text {ind}}{\sim} \textsf{N}\left(\theta_j,\sigma^2\right)\,,
$$
para $i=1,\ldots,n_j$ y $j = 1,\ldots,m$, donde $y_{i,j}$ es la variable respuesta del individuo $i$ en el grupo $j$, de forma que 

- $n_j\,\,$: número de estudiantes en el departamento $j$.
- $y_{i,j}$: puntaje de matemáticas del estudiante $i$ y en departamento $j$.

**Distribución previa jerárquica:**
$$
\theta_{j}\mid\mu,\tau^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\mu,\tau^2\right)\,,
$$
y 
$$
p(\mu,\tau^2,\sigma^2) = p(\mu)\,p(\tau^2)\,p(\sigma^2)\,,
$$
con
$$
\sigma^2\sim\textsf{GI}\left(\tfrac{\nu_0}{2},\tfrac{\nu_0\,\sigma^2_0}{2}\right)\,,\qquad
\mu\sim\textsf{N}(\mu_0,\gamma_0^2)\,,\qquad\tau^2\sim\textsf{GI}\left(\tfrac{\eta_0}{2},\tfrac{\eta_0\,\tau^2_0}{2}\right)\,.
$$

Teniendo en cuenta la información de la prueba, el modelo se ajusta utilizando los siguientes hiperparámetros: 
$$
\mu_0 = 50\qquad
\gamma^2_0 = 25\qquad
\eta_0 = 1\qquad
\tau^2_0 = 100\qquad
\nu_0 = 1\qquad
\sigma^2_0 = 100
$$
## Estimación

```{r}
# hiperparametros
mu0  <- 50 
g20  <- 25
eta0 <- 1  
t20  <- 100
nu0  <- 1  
s20  <- 100
# almacenamiento
S <- 10000
THETA <- matrix(data = NA, nrow = S, ncol = m+3)
LP    <- NULL
# valores inciales
theta <- ybar
sig2  <- var(y)
mu    <- mean(theta)
tau2  <- var(theta)
# MCMC
tictoc::tic()
set.seed(1)
for (s in 1:S) {
  # actualizar theta
  vtheta <- 1/(1/tau2 + nj/sig2)
  theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*ybar/sig2), sd = sqrt(vtheta))
  # actualizar sigma^2
  ss <- 0
  for (j in 1:m) ss <- ss + (nj[j]-1)*s2[j] + nj[j]*(ybar[j] - theta[j])^2
  sig2 <- 1/rgamma(n = 1, shape = 0.5*(nu0 + n), rate = 0.5*(nu0*s20 + ss))
  # actualizar mu
  vmu <- 1/(m/tau2+1/g20)
  mu  <- rnorm(n = 1, mean = vmu*(mu0/g20 + m*mean(theta)/tau2), sd = sqrt(vmu)) 
  # actualizar tau^2
  tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
  # almacenar valores
  THETA[s,] <- c(theta, sig2, mu, tau2)
  # log-verosimilitud
  LP[s] <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(sig2), log = T))
}
THETA <- as.data.frame(THETA)
colnames(THETA) <- c(paste0("theta", 1:m),"sig2","mu","tau2")
tictoc::toc()
# FINAL DEL ALGORITMO
```

## Convergencia

```{r, fig.width=10, fig.height=5}
# cadenas
par(mfrow=c(1,1),mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
plot(LP, xlab="Iteración", type ="l", ylab="Log-verosimilitud")
```

```{r, fig.width=10, fig.height=5}
# cadenas
par(mfrow=c(1,1),mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
plot(THETA[,m+1], xlab="Iteración", type ="l", ylab=expression(sigma^2))
```

```{r, fig.width=10, fig.height=5}
# cadenas
par(mfrow=c(1,1),mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
plot(THETA[,m+2], xlab="Iteración", type ="l", ylab=expression(mu))
```

```{r, fig.width=10, fig.height=5}
# cadenas
par(mfrow=c(1,1),mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
plot(THETA[,m+3], xlab="Iteración", type ="l", ylab=expression(tau^2))
```

```{r, fig.width=12, fig.height=4}
# autocorrelaciones
par(mfrow=c(1,3), mar=c(3,3,2.5,1),mgp=c(1.75,.75,0))
acf(THETA[,m+1], main=expression(sigma^2))
acf(THETA[,m+2], main=expression(mu))
acf(THETA[,m+3], main=expression(tau^2))
```

```{r}
# tamaños efectivos de muestra
neff_SMT <- coda::effectiveSize(THETA[,m+(1:3)])
neff_SMT
neff_THETA <- coda::effectiveSize(THETA[,1:m])
summary(neff_THETA)
```

```{r}
# errores estandar de MC : DE(parametro)/sqrt( n_eff )
apply(THETA[,m+(1:3)],2,sd)/sqrt(neff_SMT)
summary(apply(THETA[,1:m],2,sd)/sqrt(neff_THETA))
```

## Inferencia

```{r, fig.width=12, fig.height=4}
# distribuciones posteriores para mu, sigma^2 and tau^2
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
# mu
plot(density(THETA[,m+2],adj=2),xlab=expression(mu),main="",lwd=2,ylab=expression(paste(italic("p("),mu,"|",italic(y[1]),"...",italic(y[m]),")")))
abline( v=quantile(THETA[,m+2],c(.025,.5,.975)),col=c(2,4,2),lty=c(3,2,3) )
# sigma^2
plot(density(sqrt(THETA[,m+1]),adj=2),xlab=expression(sigma),main="", lwd=2,ylab=expression(paste(italic("p("),sigma,"|",italic(y[1]),"...",italic(y[m]),")")))
abline( v=quantile(sqrt(THETA[,m+1]),c(.025,.5,.975)),col=c(2,4,2),lty=c(3,2,3) )
# tau^2
plot(density(sqrt(THETA[,m+3]),adj=2),xlab=expression(tau),main="",lwd=2,ylab=expression(paste(italic("p("),tau,"|",italic(y[1]),"...",italic(y[m]),")")))
abline( v=quantile(sqrt(THETA[,m+3]),c(.025,.5,.975)),col=c(2,4,2),lty=c(3,2,3) )
```

Proporción de proporción de la variabilidad debida a la intravarianza (variabilidad dentro): 
$\eta = \sigma^2/(\sigma^2+\tau^2)$.

```{r, fig.width=6, fig.height=6}
# proporcion intravarianza
eta <- 100*THETA[,m+1]/(THETA[,m+1] + THETA[,m+3])
plot(density(eta,adj=2), xlab=expression(eta),main="",lwd=2, ylab=expression(paste(italic("p("),eta,"|",italic(y[1]),"...",italic(y[m]),")")))
abline(v=quantile(eta,c(.025,.5,.975)),col=c(2,4,2),lty=c(3,2,3))
```

```{r}
# medias posteriores
mean(THETA[,m+2])
mean(sqrt(THETA[,m+1]))
mean(sqrt(THETA[,m+3]))
```
El 99% de los puntajes dentro de los departamentos están distanciados a 3 × 13 = 39 puntos entre sí, mientras que el 99% de los puntajes promedio de los departamentos están distanciados a 3 × 9 = 27 puntos entre sí.

Además se observa que la media global es aproximadamente 54, lo cual coincide con el diseño de la prueba.

## Ranking

```{r, fig.width=10, fig.height=5}
ids  <- 1:m
ids2 <- c("Ant","Atl","Bog","Bol","Boy","Cal","Caq","Cau","Ces","Cor","Cun","Hui","Gua","Mag","Met","Nar","NSa","Qui","Ris","San","Tol","VaC","Ara","Cas","Put")
that <- colMeans(THETA[,1:m])
ic1  <- apply(X = THETA[,1:m], MARGIN = 2, FUN = function(x) quantile(x, c(0.025,0.975)))
ranking <- order(that, decreasing = T) 
ids  <- ids [ ranking]
ids2 <- ids2[ ranking]
that <- that[ ranking]
ic1  <- ic1 [,ranking]
colo <- rep(2,m)
colo[which(ic1[1,]>50)] <- 1
colo[which(ic1[2,]<50)] <- 3
colo <- c("royalblue","black","red")[colo]
# grafico
par(mfrow=c(1,1),mar=c(4,4,1.5,1),mgp=c(2.5,.75,0))
plot(NA, NA, xlab = "Departamento", ylab = "Puntaje", main = paste0("Ranking"), xlim = c(1,m), ylim = range(THETA[,1:m]), cex.axis = 0.75, xaxt = "n")
axis(side = 1, at = 1:m, labels = F)
text(x = (1:m) + 0.3, y = par("usr")[3] - 3, labels = ids2, srt = 70, pos = 2, xpd = T, cex = 0.75)
abline(v = 1:m, col = "gray95", lwd = 1, lty = 3)
abline(h = 50,  col = "gray85", lwd = 2, lty = 1)
for (j in 1:m) {
  segments(x0 = j, y0 = ic1[1,j], x1 = j, y1 = ic1[2,j], lwd = 1, col = colo[j])
  lines(x = j, y = that[j], type = "p", pch = 16, cex = 0.8, col = colo[j])
}
```

```{r, fig.width=10, fig.height=5}
ids  <- 1:m
ids2 <- c("Ant","Atl","Bog","Bol","Boy","Cal","Caq","Cau","Ces","Cor","Cun","Hui","Gua","Mag","Met","Nar","NSa","Qui","Ris","San","Tol","VaC","Ara","Cas","Put")
that <- apply(X = THETA[,1:m], MARGIN = 2, FUN = mean)
shat <- apply(X = THETA[,1:m], MARGIN = 2, FUN = sd)
cv   <- 100*shat/that
ranking <- order(that, decreasing = T) 
ids  <- ids [ ranking]
ids2 <- ids2[ ranking]
cv   <- cv[ ranking]
# grafico
par(mfrow=c(1,1),mar=c(4,4,1.5,1),mgp=c(2.5,.75,0))
plot(1:m, cv, xlab = "Departamento", ylab = "CV(%)", main = paste0("CV(%)"), pch = 19, type = "b", xlim = c(1,m), ylim = c(0,20), cex.axis = 0.75, xaxt = "n")
axis(side = 1, at = 1:m, labels = F)
text(x = (1:m) + 0.3, y = par("usr")[3] - 1.5, labels = ids2, srt = 70, pos = 2, xpd = T, cex = 0.75)
abline(v = 1:m, col = "gray95", lwd = 1, lty = 3)
abline(h = 5,  lty = 2, col = 3)
abline(h = 10, lty = 2, col = "#FFA500")
abline(h = 15, lty = 2, col = 2)
```

## Encogimiento (*shrinkage*)

```{r, fig.width=10, fig.height=5}
# encogimiento (shrinkage)
par(mfrow=c(1,2),mar=c(3,3,1,1),mgp=c(1.75,.75,0))
theta.hat<-apply(X = THETA[,1:m], MARGIN = 2, FUN = mean)
plot(ybar,theta.hat,xlab=expression(bar(italic(y))),ylab=expression(hat(theta)), pch=16, col="royalblue")
abline(0,1)
plot(nj,ybar-theta.hat,ylab=expression( bar(italic(y))-hat(theta) ),xlab="Tamaño de la muestra",  pch=16, col="royalblue")
abline(h=0)
```
